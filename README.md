ğŸ§  Multimodal RAG System: Analyzing Text & Images from PDF Documents
Welcome to the Multimodal RAG System, a robust framework that leverages Retrieval-Augmented Generation (RAG) for analyzing and understanding complex PDF documents! This tool processes both textual data and images (like graphs or charts) extracted from PDFs to provide meaningful answers to user queries. It does so by combining document retrieval and advanced language model reasoning into one seamless pipeline.

âœ¨ Key Features:
ğŸ–¼ï¸ Multimodal Processing: Analyze a mix of text, tables, and images within PDFs.
ğŸ“„ PDF Document Handling: Automatically load and process PDF files with structured chunking.
ğŸ” Intelligent Question-Answering: Ask questions about the content, and the system retrieves and generates accurate answers.
ğŸš€ RAG Pipeline: Combines retrieval of relevant content and reasoning using large language models.
ğŸ“ Project Structure
This project follows a modular approach, making it clean, extensible, and easy to maintain. Each component has a distinct responsibility, ensuring that the system can be adapted and scaled as needed.

1. loaders.py: ğŸ“„ Document Loading
This module is responsible for loading and processing PDF documents. It:

Handles high-resolution extraction of both text and images.
Chunks the content based on section titles, ensuring well-structured and manageable data for downstream processing.
Key Function:

python
Copy code
def load_pdf(file_path):
    # Loads a PDF document, extracts text, tables, and images.
2. models.py: ğŸ§  RAG Pipeline Definition
This file defines the Retrieval-Augmented Generation (RAG) pipeline. The pipeline retrieves relevant context from the document and answers user queries using advanced language models.

Incorporates custom functions to format multimodal prompts.
Handles both document retrieval and language model reasoning.
Key Function:

python
Copy code
def build_multimodal_rag():
    # Constructs and returns the multimodal RAG chain for querying.
3. prompts.py: ğŸ“ Prompt Formatting
In this module, we define how the input data (text, images, user queries) are combined into a format that the language model can understand. It:

Merges text and images into a cohesive prompt.
Formats the user question alongside the document context for accurate answers.
Key Function:

python
Copy code
def multimodal_prompt_function(data_dict):
    # Formats the text and images into a structured prompt for the model.
4. utils.py: ğŸ› ï¸ Helper Functions
This file contains utility functions that assist in data manipulation and modular processing. These utilities are reusable across different parts of the project.

Splits images and texts into separate components for processing.
Key Function:

python
Copy code
def split_image_text_types(data):
    # Splits the loaded data into text and image components.
5. main.py: ğŸ¬ Entry Point & User Interface (Streamlit)
This is the main entry point of the system where:

Users can upload PDF files via a simple Streamlit graphical user interface (GUI).
The RAG pipeline is executed to analyze the document and respond to user queries.
Streamlit Features:

File upload: Choose a PDF document from your system.
Query input: Ask questions about the uploaded document.
Answer generation: Get responses from the RAG pipeline based on the document's content.
ğŸ› ï¸ How to Run the Project
Clone the repository:

bash
Copy code
git clone https://github.com/your-username/multimodal-rag-system.git
cd multimodal-rag-system
Install the dependencies: Make sure you have a virtual environment set up, then run:

bash
Copy code
pip install -r requirements.txt
Run the Streamlit app: Launch the web interface to upload your PDF and ask questions:

bash
Copy code
streamlit run main.py
Upload your PDF and interact with the system. Ask any relevant questions about the document, and the system will retrieve and generate the answers using the RAG pipeline.

ğŸ” Example Usage
Upload PDF: Upload any document containing text, tables, and images (e.g., a research paper, report, or company presentation).
Enter Query: Ask a question like "What are the main categories of the features offered?".
Receive Answer: The system analyzes the text and images and returns a comprehensive answer based on the document's content.
ğŸ“š Technologies Used
LangChain: For chaining together RAG processes.
Streamlit: For providing a simple, user-friendly GUI.
OpenAI GPT: As the backend for language understanding and reasoning.
Python: The core language for building this system.
ğŸ™Œ Contributing
We welcome contributions! Feel free to fork the repository, make enhancements, and submit a pull request. Let's make document analysis smarter and more efficient together! ğŸš€

ğŸ“„ License
This project is licensed under the MIT License. Feel free to use, modify, and distribute this code.

